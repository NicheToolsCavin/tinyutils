<p>
  WordPress has a plugin for everything.
  That’s a blessing, and also how you end up with a site that loads like it’s powered by a lemon.
</p>

<p>
  If you’re trying to find broken links on a WordPress site, you have two main options:
  <strong>scan from inside WordPress (plugin)</strong> or <strong>scan from outside (web tool / crawler)</strong>.
  Here’s the honest comparison.
</p>

<h2 id="tldr">TL;DR</h2>
<ul>
  <li><strong>Want the simplest and safest for performance?</strong> Use an external web tool.</li>
  <li><strong>Want in-dashboard editing and scheduled scans?</strong> A plugin can help (but watch load).</li>
  <li><strong>Running a big audit?</strong> External scan first, then fix internally.</li>
</ul>

<h2 id="plugins">WordPress broken link checker plugins</h2>

<h3>Pros</h3>
<ul>
  <li><strong>Runs inside WordPress</strong> (can see internal content and sometimes draft areas).</li>
  <li><strong>Convenient editing</strong> (fix links right from the dashboard).</li>
  <li><strong>Scheduling</strong> (runs periodically without you thinking about it).</li>
</ul>

<h3>Cons</h3>
<ul>
  <li><strong>Performance overhead</strong> (crawling is work, and your server pays the bill).</li>
  <li><strong>Hosting limits</strong> (shared hosts and managed WP can throttle long scans).</li>
  <li><strong>WP cron weirdness</strong> (scheduled tasks are not always reliable).</li>
</ul>

<h2 id="webtools">Web tools / external crawlers</h2>
<p>
  External tools scan your site like a user/bot would: from the outside.
  That means no plugin install and no server load from crawling.
</p>

<h3>Pros</h3>
<ul>
  <li><strong>No install</strong> (you can run it today).</li>
  <li><strong>No WP performance hit</strong> (the crawling happens externally).</li>
  <li><strong>Exports</strong> (CSV results are perfect for fixing or delegating).</li>
</ul>

<h3>Cons</h3>
<ul>
  <li><strong>Public access required</strong> (if content is gated behind login, it may be missed).</li>
  <li><strong>Some JS-heavy links can be missed</strong> unless the crawler renders JS.</li>
</ul>

<p>
  If you want a simple external scan with exportable results, use
  <a href="/tools/dead-link-finder/">TinyUtils Dead Link Finder</a>.
</p>

<h2 id="what-scanned">What each approach actually scans</h2>
<p>
  This is the part people miss, and it explains a lot of “why are our reports different?” arguments:
</p>
<ul>
  <li>
    <strong>Plugins</strong> often scan your WordPress database: posts, pages, and sometimes custom fields.
    They can catch links that aren’t publicly crawlable yet (drafts, private pages).
  </li>
  <li>
    <strong>External tools</strong> crawl what a visitor can reach.
    They’re better at catching real-world problems (template links, nav/footer issues, redirects/404s), but they won’t see content behind a login wall.
  </li>
</ul>
<p>
  Neither is “more correct” — they’re answering slightly different questions.
  Pick the one that matches the problem you’re trying to solve.
</p>

<h2 id="pick">When to pick each (quick guide)</h2>
<table>
  <thead>
    <tr>
      <th>Your situation</th>
      <th>Pick</th>
      <th>Why</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Small blog, occasional checks</td>
      <td>Web tool</td>
      <td>Fast, no overhead, easy exports</td>
    </tr>
    <tr>
      <td>You need in-dashboard fixing</td>
      <td>Plugin</td>
      <td>Convenient editing inside WP</td>
    </tr>
    <tr>
      <td>High-traffic site, performance sensitive</td>
      <td>Web tool</td>
      <td>No server load from crawling</td>
    </tr>
    <tr>
      <td>Agency doing audits + handoff</td>
      <td>Web tool + exports</td>
      <td>CSV handoff is cleaner than screenshots</td>
    </tr>
  </tbody>
</table>

<h2 id="workflow">A workflow that doesn’t make you hate your life</h2>
<p>
  If you have more than a handful of broken links, treat it like a bug triage problem:
</p>
<ol>
  <li><strong>Scan externally first</strong> to catch the high-impact stuff (nav/footer, popular pages, obvious 404s).</li>
  <li><strong>Export the report</strong> so you can sort by “where it’s found” and fix in batches.</li>
  <li><strong>Fix inside WordPress</strong> (or your editor) so internal links don’t rely on redirects long-term.</li>
  <li><strong>Re-scan</strong> to confirm you didn’t create new issues while fixing old ones.</li>
  <li><strong>Only then</strong> consider a plugin if you want ongoing monitoring inside the dashboard.</li>
</ol>
<p>
  The big win is avoiding “hero mode.” You don’t need to fix 2,000 links in one sitting.
  You need to stop broken links from quietly piling up for the next six months.
</p>

<h2 id="tips">Migration tips (so you don’t make it worse)</h2>
<p>
  Treat broken links like a bug list: sort by impact, fix the obvious stuff first (nav/footer/top pages), then re-scan.
  The goal isn’t “zero broken links” in a single heroic sprint — it’s “broken links stop quietly piling up.”
</p>
<ul>
  <li>
    <strong>Don’t scan during peak traffic.</strong> Crawls can spike CPU and DB load.
  </li>
  <li>
    <strong>Export results.</strong> Treat it like a bug list, not a one-time report.
  </li>
  <li>
    <strong>Fix internal links directly.</strong> Redirects are useful, but internal links shouldn’t rely on them forever.
  </li>
  <li>
    <strong>Re-scan after fixes.</strong> Broken links are a regression-prone feature.
  </li>
  <li>
    <strong>Watch redirects vs 404s.</strong> A 301 isn’t “broken,” but it’s still worth fixing internal links so you don’t chain redirects forever.
  </li>
  <li>
    <strong>Expect some false alarms.</strong> Some sites rate-limit crawlers and respond with 403/429 even though the page is “fine” for normal users.
  </li>
</ul>

<h2 id="next">Next steps</h2>
<p>
  If you want the lowest-friction option, start with
  <a href="/tools/dead-link-finder/">TinyUtils Dead Link Finder</a>.
  Export the results and fix the top issues first (nav, footer, top pages).
  That’s usually 80% of the payoff.
</p>
