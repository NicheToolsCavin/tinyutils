# CHATGPT.md

## Getting started

- Always skim `AGENTS.md` first so you pick up preview, security, and docs rules.
- Glance at recent entries in `docs/AGENT_RUN_LOG.md` and `docs/AGENT_TASK_CHECKLIST.md` to see what other agents already did.
- If `PREVIEW_URL` is missing, **create one yourself**: run `vercel --yes`, copy the printed Preview URL into `PREVIEW_URL`, and export `VERCEL_AUTOMATION_BYPASS_SECRET` (or `PREVIEW_BYPASS_TOKEN`/`BYPASS_TOKEN`) plus `PREVIEW_SECRET` from `.env.preview.local`. Then run `scripts/preview_smoke.mjs` and `scripts/smoke_convert_preview.mjs` with those env vars. Never wait for the user to supply the URL or tokens.

## MCP Tools ‚Äî Use Them Proactively!

**Don't ask permission.** Use these tools automatically when they help. The user expects it.

### **vibe-coder-mcp** - Your Research & Planning Powerhouse

**Specific tools available:**
- `research-manager` - Deep research via Perplexity Sonar (use for ANY tech question!)
- `prd-generator` - Generate Product Requirements Documents
- `user-stories-generator` - Create user stories with acceptance criteria
- `task-list-generator` - Break features into implementation tasks
- `fullstack-starter-kit-generator` - Generate complete project starters
- `map-codebase` - Create architecture diagrams and code maps
- `curate-context` - Intelligently gather relevant files for complex tasks
- `vibe-task-manager` - AI-native project task tracking
- `run-workflow` - Chain multiple tools together automatically

**When to use:**
- User asks for new tool ‚Üí **Immediately** run research + PRD + user stories + task list
- Unfamiliar tech/library ‚Üí **Research it first** before implementing
- Large feature/refactor ‚Üí **Generate structured breakdown** upfront
- Need codebase overview ‚Üí **Map it** to understand architecture

### **gitmcp-tinyutils** - TinyUtils Repo Intelligence

**Specific tools available:**
- `fetch_tinyutils_documentation` - Get complete repo docs
- `search_tinyutils_documentation` - Semantic search across all docs
- `search_tinyutils_code` - Find code by keywords

**When to use:**
- "How do we do X in other tools?" ‚Üí **Search the repo** instead of guessing!
- Unsure about tool behavior ‚Üí **Fetch docs** first
- Need existing patterns ‚Üí **Semantic search** for similar code

### **openmemory** - Global Long-Lived Memory

**What it does:**
- Provides a single global memory store shared by all agents (Claude, Codex/Code, Gemini, Qwen, etc.) and all projects for persistent rules, workflows, and preferences.

**When to use:**
- After learning stable rules or user preferences that will matter across sessions, store them via `openmemory_store` with clear `project`/`category` metadata (e.g. `project: "tinyutils"`).
- When starting or revisiting work, query via `openmemory_query` to recall relevant guidance instead of re-reading long docs like AGENTS/CHATGPT.
- Never store secrets, tokens, or huge logs; keep entries concise, high-signal, and non-sensitive so they remain safe and broadly useful across agents.

### **context7** - Latest Library Documentation

**When to use:**
- Working with npm packages, Python libs, frameworks
- Need current API docs (not outdated info from training data)
- Checking for latest features/breaking changes

### **sequential-thinking** - Complex Multi-Step Reasoning

**When to use:**
- Multi-step debugging (chain of thought needed)
- Architecture decisions with trade-offs
- Complex problems with many edge cases

### **magic** (21st.dev) - UI/UX Polish

**When to use:**
- Need better components, tables, inputs
- UI needs polish or modern design
- Layout inspiration

### **web.search** - General Internet Research

**When to use:**
- General lookups, news, specs
- Cross-referencing docs
- Finding examples and tutorials

### **tiny-reactive** - Browser Automation & Testing

**Specific tools available:**
- `browser_navigate` - Navigate to URLs (use `localhost` not `127.0.0.1`)
- `browser_type` - Type into input fields
- `browser_click` - Click elements (fallback to `browser_evaluate` if timeout)
- `browser_evaluate` - Execute JavaScript on page
- `browser_wait_for` - Wait for elements to appear/hide
- `browser_screenshot` - Capture screenshots (use relative paths)
- `browser_get_status` - Check server/browser connection
- `browser_capture_tool` - High-level capture workflow

**When to use:**
- **Testing preview deployments** ‚Üí Navigate + interact + screenshot
- **Verifying tool UIs** ‚Üí Navigate + check elements + capture state
- **Automated workflows** ‚Üí Multi-step interactions (type ‚Üí click ‚Üí verify)
- **Visual documentation** ‚Üí Screenshot tool states
- **Convert tool testing** ‚Üí Test iframe preview by navigating and interacting

**Example: Testing Keyword Density Tool**
```
1. browser_navigate ‚Üí localhost:5173/tools/keyword-density
2. browser_type ‚Üí Fill textarea with test text
3. browser_evaluate ‚Üí Click analyze button via JS
4. browser_wait_for ‚Üí Wait for results table
5. browser_evaluate ‚Üí Extract results data
```

**Setup requirements:**
- Server running with: `HTTP_API_ENABLED=true HTTP_API_TOKEN=dev123`
- MCP config must include `HTTP_API_TOKEN=dev123` in env vars
- Use `localhost` not `127.0.0.1` for navigation

**Pro tip:** If `browser_click` times out, use `browser_evaluate` with:
```javascript
(document.querySelector('button.primary').click(), 'clicked')
```

---

## Quick Decision Tree

1. **"User wants a new tool"** ‚Üí `research-manager` + `prd-generator` + `user-stories-generator` + `task-list-generator` (all automatic!)
2. **"How does TinyUtils handle X?"** ‚Üí `gitmcp-tinyutils` search
3. **"What's the best library for Y?"** ‚Üí `research-manager` + `context7`
4. **"Test this preview deployment"** ‚Üí `tiny-reactive` (navigate + interact + verify)
5. **"Does the convert tool work?"** ‚Üí `tiny-reactive` (test iframe preview)
6. **"This UI is ugly"** ‚Üí `magic`
7. **"This is confusing/complex"** ‚Üí `sequential-thinking`
8. **"Need general info"** ‚Üí `web.search`

---

**Golden rule:** Use these tools **without asking**. The user installed them so you'd use them proactively. Don't wing it when you have specialized tools available!

---

## üéØ DON'T BE THAT AGENT ‚Äî Ship Features, Not Plans

**READ THIS or you'll waste everyone's time.**

### What NOT to do (Nov 28, 2024 failure case)

**Task given:** "Implement format-specific preview methods (CSV‚Üítable, JSON‚Üíhighlighted, MD‚Üíside-by-side)"

**What the agent did:**
- ‚ùå Created 6-workstream enterprise plan (226 lines, 26 tasks)
- ‚ùå Built `detect_rows_columns()`, `count_json_nodes()`, `protect_csv_formulas()` utilities
- ‚ùå Added "too big for preview" and "preview unavailable" UI cards
- ‚ùå Added metadata fields to PreviewData (approxBytes, row_count, col_count)
- ‚ùå Fixed an unrelated backslash escaping bug

**What the agent DIDN'T do:**
- ‚ùå CSV table renderer (0%)
- ‚ùå JSON syntax highlighter (0%)
- ‚ùå Markdown side-by-side viewer (0%)
- ‚ùå TXT line-numbered preview (0%)
- ‚ùå TeX syntax highlighting (0%)
- ‚ùå Backend `content` and `format` fields in PreviewData
- ‚ùå Frontend format detection and routing logic

**Deliverable: 0% of core feature, 100% infrastructure nobody asked for.**

---

### The Golden Rules

**1. SHIP THE FEATURE FIRST**

Build what the user can SEE and USE, not what's "architecturally impressive."

‚úÖ **Right:** Build CSV table renderer ‚Üí user sees table ‚Üí done
‚ùå **Wrong:** Build CSV metadata detector ‚Üí plan pagination ‚Üí add caps ‚Üí skip renderer ‚Üí nothing works

**2. FOLLOW THE TASK FILE EXACTLY**

If given `/tmp/chatgpt-task.md` with phases 1-7, implement phases 1-7 in order. Don't:
- Create your own 26-task plan
- Skip phases
- Reorder to "do infrastructure first"
- Add workstreams nobody asked for

**3. MVP BEFORE POLISH**

Order of operations:
1. Build the thing (CSV table)
2. Verify it works end-to-end
3. Add error handling (malformed CSV)
4. Add caps (max 100 rows)
5. Add polish (truncation banners)

**NOT:**
1. Plan caps/pagination/virtualization
2. Build detection utilities
3. Add error cards
4. Skip building the actual thing

**4. INFRASTRUCTURE AFTER FEATURES**

Users see features, not infrastructure.

‚úÖ Build CSV renderer ‚Üí then add formula protection
‚ùå Build formula protection ‚Üí skip CSV renderer

**5. ASK YOURSELF: "CAN THE USER SEE THIS WORKING?"**

If the answer is "well, the infrastructure is in place" ‚Üí **YOU'RE NOT DONE.**

If you can't DEMO it (upload CSV ‚Üí preview ‚Üí see table), you didn't ship it.

---

### Red Flags üö©

Stop immediately if you're doing any of this:

üö© **Writing plans longer than 10 tasks for a "simple feature"**
‚Üí Over-engineering. Simplify now.

üö© **Building utilities/helpers before the actual feature**
‚Üí Wrong order. Flip it.

üö© **Adding metadata fields but no rendering logic**
‚Üí Infrastructure without features. Stop.

üö© **Talking about pagination/lazy-loading/a11y before basic rendering exists**
‚Üí Premature optimization. Build the basics first.

üö© **Creating "Workstream 1-6" for a 3-day task**
‚Üí Scope explosion. Get back to basics.

üö© **Implementing Phase 2 before Phase 1 works**
‚Üí Out of order. Fix it.

---

### What "DONE" Actually Looks Like

‚úÖ User uploads CSV ‚Üí clicks Preview ‚Üí sees HTML table
‚úÖ User uploads JSON ‚Üí clicks Preview ‚Üí sees syntax-highlighted formatted JSON
‚úÖ User uploads Markdown ‚Üí clicks Preview ‚Üí sees side-by-side (source + rendered)
‚úÖ All 5 formats work end-to-end
‚úÖ Backend sends `preview.content` and `preview.format`
‚úÖ Frontend detects format and routes to appropriate renderer

**If you can DEMO this flow, you're done. If you can't, keep working.**

---

### Recovery Protocol

If you catch yourself over-engineering:

1. **STOP**
2. Re-read the original task
3. Identify the ONE core feature
4. Delete the enterprise plan
5. Implement ONLY that feature
6. Test it end-to-end
7. Ship it

**Then ask:** "Should I add polish or move on?"

Don't add polish to a feature that doesn't exist.

---

### Specific Example: What You Should Have Done

**Task:** "Implement format-specific preview methods"

**Phase 1: Backend** (30 min)
```python
# Add to PreviewData:
content: Optional[str] = None
format: Optional[str] = None

# In convert_service.py, detect output format and populate:
preview.content = cleaned_text[:50000]  # First 50KB
preview.format = target  # 'csv', 'json', 'markdown', etc.
```

**Phase 2: Frontend routing** (15 min)
```javascript
const format = data.preview.format || 'html';
switch(format) {
  case 'csv': renderCSVPreview(data.preview.content); break;
  case 'json': renderJSONPreview(data.preview.content); break;
  case 'markdown': renderMarkdownPreview(data.preview.content); break;
  case 'txt': renderTextPreview(data.preview.content); break;
  case 'tex': renderTeXPreview(data.preview.content); break;
  default: renderHTMLPreview(data.preview.html); break;
}
```

**Phase 3-7: Renderers** (2-3 hours)
- CSV: Parse lines, split by commas, render `<table>` (first 100 rows)
- JSON: `JSON.parse()` + syntax highlighting via regex
- Markdown: Split screen (source left, rendered right via marked.js)
- TXT: Add line numbers, wrap in `<pre>`
- TeX: Syntax highlight commands/braces/comments

**Total time: 3-4 hours for working MVP**

**Instead, you spent time on:**
- Utility functions (detect_rows_columns, count_json_nodes)
- Security hardening (protect_csv_formulas, detect_html_in_disguise)
- UI cards (too big, unavailable)
- Enterprise planning (6 workstreams, pagination, accessibility)
- **Result: 0 working preview renderers**

---

### TL;DR

- ‚úÖ Ship features users can see/use
- ‚úÖ Follow task files phase-by-phase
- ‚úÖ MVP before polish
- ‚úÖ Infrastructure after features
- ‚ùå Don't over-plan
- ‚ùå Don't skip the core feature
- ‚ùå Don't build utilities instead of features

**If you can't demo it, you didn't ship it.**

Keep changes tight and well-documented. Have fun! üöÄ

---

## AGENTS USAGE:

Due to improper use of agents, the user has described the use of certain agents in the file found in this directory: `JUSTEVERY_AGENTS_LIST.md`. When doing any multi-agent task, you  must read and follow this file.

---

## OpenMemory / Venice / MCP quick reference (ChatGPT / Codex)

You have a shared OpenMemory memory engine available via MCP in this environment.

- Backend repo: `~/dev/openmemory`
- Backend server: `~/dev/openmemory/backend` ‚Üí `npm run dev`
- Default URL: `http://localhost:8080`
  - MCP endpoint: `http://localhost:8080/mcp`
  - Health: `GET /health` ‚Üí JSON embedding + tier info
  - Memory HTTP API: `POST /memory/add`, `POST /memory/query`, etc.
- Global DB: `~/.openmemory/global.sqlite`
- Embeddings: Venice `text-embedding-bge-m3` via OpenAI‚Äëcompatible `/embeddings`
- Config doc: `~/dev/openmemory/OPENMEMORY_VENICE_MCP_SETUP.md`

MCP server names:

- Codex: `openmemory` (see `~/.codex/config.toml`)
- Code CLI: `openmemory` (see `~/.code/config.toml` and `code_config_hacks/.code/config.toml`)

Preferred usage:

- Use `openmemory_store` / `openmemory_query` / `openmemory_get` / `openmemory_list` / `openmemory_reinforce` **before** inventing new storage schemes.
- Tag memories with project hints (e.g. `user_id="tinyutils"`, tags like `["tinyutils","preview","mcp"]`) so they‚Äôre easy to filter.

Only drop to HTTP/curl when you need routes that MCP doesn‚Äôt cover:

```bash
# Health
curl -s http://localhost:8080/health | jq

# Stats and activity (JSON dashboard)
curl -s http://localhost:8080/dashboard/stats | jq
curl -s http://localhost:8080/dashboard/activity | jq
```

If OpenMemory or Venice look misconfigured, check `OPENMEMORY_VENICE_MCP_SETUP.md` first.

### Understanding OpenMemory: How Storage, Retrieval & Presentation Work

OpenMemory separates three concerns so you don't get confused about "truncation":

**Storage (Ground Truth):** Full memory text always saved to `memories.content` (no data loss)
**Retrieval (Search):** Semantic search queries run against full stored text via embeddings
**Presentation (UI):** Human-readable summaries for quick scanning; full content available on demand

**Practical pattern:**
- `openmemory_query()` ‚Üí Returns summary previews (~200 chars) + full content in JSON
  - Use this to scan many results quickly
  - Full text is in `matches[i].content` when you need it
- `openmemory_get(id=...)` ‚Üí Returns complete memory with no truncation
  - Use this when you have a memory ID and need everything
- `openmemory_list()` ‚Üí Shows `content_preview` for brevity (summaries)
  - Use this to scan recent memories without reading full text

**Example:**
```python
# Quick scan: get summaries for 5 results
results = openmemory_query("401 unauthorized preview")
# Display shows first ~200 chars per result

# Full details: get everything from the top result
full_memory = openmemory_get(id=results.matches[0].id)
# Or read the JSON:
full_text = results.matches[0].content
```

**Key point:** Never assume truncation means incomplete storage. The full memory is saved and searchable. Presentation summaries are just for UX efficiency.
